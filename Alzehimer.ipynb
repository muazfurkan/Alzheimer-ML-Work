{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVBzOWDIMJpu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/alzheimer/alzheimer_gs.csv\")\n",
        "\n",
        "data = df.iloc[:,:-2]\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "label = df['label']\n",
        "experiment_label = df['ds']"
      ],
      "metadata": {
        "id": "4IXVLKqmMzB0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_label = len(np.unique(label))\n",
        "len_experiment = len(np.unique(experiment_label))\n",
        "class_count = len_label * len_experiment"
      ],
      "metadata": {
        "id": "wM72RTl3PzOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MY TOOLS\n",
        "\n",
        "class reduction:\n",
        "  \n",
        "  def __init__(self,\n",
        "               train_data,\n",
        "               dimension):\n",
        "    \n",
        "    self.train_data = train_data\n",
        "    self.dimension = dimension\n",
        "\n",
        "  def pca(self):\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    pca = PCA(n_components=self.dimension)\n",
        "    reducted_data = pca.fit_transform(self.train_data)\n",
        "\n",
        "    return reducted_data\n",
        "\n",
        "  def kernel_pca(self,\n",
        "                 kernel):\n",
        "    \n",
        "    from sklearn.decomposition import KernelPCA\n",
        "\n",
        "    k_pca = KernelPCA(n_components=self.dimension, kernel=kernel)\n",
        "    reducted_data = k_pca.fit_transform(self.train_data)\n",
        "\n",
        "    return reducted_data\n",
        "\n",
        "  def svd(self):\n",
        "    from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "    svd = TruncatedSVD(n_components=self.dimension)\n",
        "    reducted_data = svd.fit_transform(self.train_data)\n",
        "\n",
        "    return reducted_data\n",
        "\n",
        "  def umap(self,\n",
        "           neighbors,\n",
        "           metric):\n",
        "    \n",
        "    try:\n",
        "      import umap\n",
        "    except ImportError:\n",
        "      !pip install umap-learn\n",
        "      import umap\n",
        "\n",
        "    umap = umap.UMAP(n_neighbors=neighbors, n_components=self.dimension, metric=metric)\n",
        "    embedding = umap.fit_transform(self.train_data)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "\n",
        "\n",
        "class metrics:\n",
        "\n",
        "  def __init__(self,\n",
        "               data,\n",
        "               predicted_labels):\n",
        "    \n",
        "    self.data = data\n",
        "    self.predicted_labels = predicted_labels\n",
        "\n",
        "  def silhouette(self):\n",
        "    from sklearn.metrics import silhouette_score\n",
        "\n",
        "    acc_score = silhouette_score(self.data, self.predicted_labels, metric='euclidean')\n",
        "    \n",
        "    return acc_score\n",
        "\n",
        "  def f1_score(self):\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    acc_score = f1_score(self.data, self.predicted_labels)\n",
        "\n",
        "    return acc_score\n",
        "\n",
        "  def roc_auc(self,\n",
        "              predicted_prob,\n",
        "              multiclass):\n",
        "    \n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    if multiclass:\n",
        "      acc_score = roc_auc_score(self.data, predicted_prob, multiclass='ovr')\n",
        "\n",
        "    else: \n",
        "      acc_score = roc_auc_score(self.data, predicted_prob)\n",
        "\n",
        "    return acc_score\n",
        "\n",
        "  def simple_acc(self):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    acc_score = accuracy_score(self.data, self.predicted_labels)\n",
        "\n",
        "    return acc_score\n",
        "\n",
        "  def confusion_matrix(self):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(data, self.predicted_labels)\n",
        "\n",
        "    return cm\n",
        "\n",
        "\n",
        "\n",
        "class algorithms:\n",
        "\n",
        "  def __init__(self,\n",
        "               train_data,\n",
        "               train_labels=None,\n",
        "               test_data=None,\n",
        "               test_labels=None):\n",
        "    \n",
        "    self.random_state = 42\n",
        "    self.train_data = train_data\n",
        "    self.train_labels = train_labels\n",
        "    self.test_data = test_data\n",
        "    self.test_labels = test_labels\n",
        "\n",
        "  def kmeans(self,\n",
        "             class_count):\n",
        "    \n",
        "    model = {}\n",
        "    \n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    kmeans = KMeans(n_clusters=class_count, random_state=self.random_state, n_init=20)\n",
        "    kmeans.fit(self.train_data)\n",
        "\n",
        "    acc = metrics(self.train_data, kmeans.labels_)\n",
        "    acc_score = acc.silhouette()\n",
        "\n",
        "    model['model'] = kmeans\n",
        "    model['labels'] = kmeans.labels_\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def dbscan(self,\n",
        "             eps,\n",
        "             min_samples):\n",
        "    \n",
        "    model = {}\n",
        "\n",
        "    from sklearn.cluster import DBSCAN\n",
        "\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    dbscan.fit(self.train_data)\n",
        "\n",
        "    acc = metrics(self.train_data, dbscan.labels_)\n",
        "    acc_score = acc.silhouette()\n",
        "\n",
        "    model['model'] = dbscan\n",
        "    model['labels'] = dbscan.labels_\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def svm(self,\n",
        "          kernel,\n",
        "          c):\n",
        "    \n",
        "    model = {}\n",
        "    \n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    svm = SVC(kernel=kernel, C=c, random_state=self.random_state)\n",
        "    svm.fit(self.train_data, self.train_labels)\n",
        "    predictions = svm.predict(self.test_data)\n",
        "\n",
        "    acc = metrics(self.test_labels, predictions)\n",
        "    acc_score = acc.simple_acc()\n",
        "\n",
        "    model['model'] = svm\n",
        "    model['labels'] = predictions\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def dtc(self):\n",
        "\n",
        "    model = {}\n",
        "\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "    dtc = DecisionTreeClassifier()\n",
        "    dtc.fit(self.train_data, self.train_labels)\n",
        "    predictions = dtc.predict(self.test_data)\n",
        "\n",
        "    acc = metrics(self.test_labels, predictions)\n",
        "    acc_score = acc.simple_acc()\n",
        "\n",
        "    model['model'] = dtc\n",
        "    model['labels'] = predictions\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def rf(self,\n",
        "         n_estimators,\n",
        "         max_depth,\n",
        "         max_features):\n",
        "    \n",
        "    model = {}\n",
        "    \n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
        "    rf.fit(self.train_data, self.train_labels)\n",
        "    predictions = rf.predict(self.test_data)\n",
        "\n",
        "    acc = metrics(self.test_labels, predictions)\n",
        "    acc_score = acc.simple_acc()\n",
        "\n",
        "    model['model'] = rf\n",
        "    model['labels'] = predictions\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def mlp(self,\n",
        "          layers,\n",
        "          activation_func,\n",
        "          loss,\n",
        "          optimizer,\n",
        "          metric,\n",
        "          epochs):\n",
        "    \n",
        "    model = {}\n",
        "    \n",
        "    try:\n",
        "      from tensorflow.keras.models import Sequential\n",
        "      from tensorflow.keras.layers import Dense\n",
        "    except ImportError:\n",
        "      !pip install tensorflow\n",
        "      from tensorflow.keras.models import Sequential\n",
        "      from tensorflow.keras.layers import Dense\n",
        "\n",
        "    mlp = Sequential()\n",
        "    for i in layers:\n",
        "      mlp.add(Dense(layers[i], input_dim=self.train_data.shape[1], activation=activation_func))\n",
        "\n",
        "    mlp.add(Dense(1, activation='sigmoid'))\n",
        "    mlp.compile(loss=loss, optimizer=optimizer, metrics=metric)\n",
        "    mlp.fit(self.train_data, self.train_labels, epochs=epochs)\n",
        "\n",
        "    threshold = 0.5\n",
        "    \n",
        "    predictions = mlp.predict(self.test_data)\n",
        "    predictions = np.where(predictions > threshold, 1, 0)\n",
        "    prediction = np.squeeze(predictions)\n",
        "\n",
        "    acc = metrics(self.test_labels, predictions)\n",
        "    acc_score = acc.simple_acc()\n",
        "\n",
        "    model['model'] = mlp\n",
        "    model['labels'] = predictions\n",
        "    model['acc'] = acc_score\n",
        "\n",
        "    return model\n",
        "\n",
        "  def pca(self,\n",
        "          dimension):\n",
        "    \n",
        "    pca = reduction(self.train_data, dimension)\n",
        "\n",
        "    return pca.pca()\n",
        "\n",
        "  def kernel_pca(self,\n",
        "                 dimension,\n",
        "                 kernel):\n",
        "    \n",
        "    k_pca = reduction(self.train_data, dimension)\n",
        "\n",
        "    return k_pca.kernel_pca(kernel)\n",
        "\n",
        "  def svd(self,\n",
        "          dimension):\n",
        "    \n",
        "    svd = reduction(self.train_data, dimension)\n",
        "\n",
        "    return svd.svd()\n",
        "\n",
        "  def umap(self,\n",
        "           neighbors,\n",
        "           dimension,\n",
        "           metric):\n",
        "    umap = reduction(self.train_data, dimension)\n",
        "    \n",
        "    return umap.umap(neighbors, metric)"
      ],
      "metadata": {
        "id": "CFP1epX0KVdu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer = algorithms(data)\n",
        "PCA_data = reducer.pca(2)"
      ],
      "metadata": {
        "id": "rV77TKuLle54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(PCA_data, label, test_size=0.2, random_state=42)\n",
        "\n",
        "algorithm = algorithms(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test)\n",
        "results = {}\n",
        "layers = {\n",
        "    '1':50,\n",
        "    '2':50,\n",
        "    '3':50\n",
        "    }"
      ],
      "metadata": {
        "id": "_qcRv51BbQt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = algorithm.svm('rbf', 2.1493544617380334)"
      ],
      "metadata": {
        "id": "YlICREB587UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = algorithm.dtc()"
      ],
      "metadata": {
        "id": "zAsqucDn8_HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = algorithm.rf(n_estimators=526,\n",
        "                  max_depth=3,\n",
        "                  max_features='sqrt')"
      ],
      "metadata": {
        "id": "3_JXdTZs8_pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = algorithm.mlp(layers=layers,\n",
        "                    activation_func='relu',\n",
        "                    loss='binary_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metric=['accuracy'],\n",
        "                    epochs=100)"
      ],
      "metadata": {
        "id": "t7bElYob9Bum"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm_names = ['SVM', 'DTC', 'RF', 'MLP']\n",
        "scores = [svm['acc'], dtc['acc'], rf['acc'], mlp['acc']]\n",
        "\n",
        "colors = ['#cd853f', '#c1cdc1', '#4a708b', '#ff6a6a']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.bar(algorithm_names, scores, color=colors)\n",
        "\n",
        "percentage_scores = [str(int(score*100)) + \"%\" for score in scores]\n",
        "\n",
        "for i, v in enumerate(scores):\n",
        "    ax.text(i, v+0.01, percentage_scores[i], ha='center', fontsize=12)\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Classification Algorithm Comparison')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "56oYzyNTfXK2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reducer = algorithms(train_data=data)\n",
        "embedding = reducer.umap(80, 15, 'euclidean')"
      ],
      "metadata": {
        "id": "KwOpZtuEPZrl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = algorithms(embedding)\n",
        "labels = {}\n",
        "samples_count = embedding.shape[0]\n",
        "\n",
        "min_samples = int(samples_count / class_count)\n",
        "kmeans = cluster.kmeans(2)\n",
        "dbscan = cluster.dbscan(5, min_samples)"
      ],
      "metadata": {
        "id": "Nbz4ynhRuoib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(embedding[:, 0], embedding[:, 1], c=kmeans['labels'], s=50, cmap='plasma')\n",
        "plt.title(f\"UMAP KMEANS Score : {kmeans['acc']}\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1], c=dbscan['labels'], s=50, cmap='plasma')\n",
        "plt.title(f\"UMAP DBSCAN Score : {dbscan['acc']}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CALt-m2svEV9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "import seaborn as sns\n",
        "\n",
        "results = []\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
        "\n",
        "dtc_model1 = DecisionTreeClassifier()\n",
        "dtc_model2 = DecisionTreeClassifier()\n",
        "dtc_model3 = DecisionTreeClassifier()\n",
        "svm_model = SVC(kernel='rbf')"
      ],
      "metadata": {
        "id": "vIbHKtMMMx9y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data dimensionally reduced with UMAP gets an acc score of 0.66\n",
        "\n",
        "rfe = RFE(estimator=dtc_model1, n_features_to_select=500)\n",
        "X_rfe = rfe.fit_transform(X_train, y_train)\n",
        "rfe_pred = rfe.predict(X_test)\n",
        "results.append(rfe_pred)\n",
        "\n",
        "score = metrics(y_test, rfe_pred)\n",
        "acc = score.simple_acc()\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "GwpN4iucgQv1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It gets an acc score of 0.60 on data without any dimension reduction.\n",
        "\n",
        "dtc_model2.fit(X_train, y_train)\n",
        "dtc_pred = dtc_model2.predict(X_test)\n",
        "\n",
        "importances = dtc_model2.feature_importances_\n",
        "sorted_indices = np.argsort(importances)[::-1]\n",
        "sorted_importances = importances[sorted_indices]\n",
        "\n",
        "importances = []\n",
        "count = 0\n",
        "\n",
        "for i, val in enumerate(sorted_importances):\n",
        "  if i<20 and val!=0.0:\n",
        "    print(val)\n",
        "    count += 1\n",
        "    importances.append(val)\n",
        "  if val==0.0:\n",
        "    break\n",
        "\n",
        "selected_cols = data.columns[sorted_indices[::-20][-count:]]\n",
        "\n",
        "final_df = pd.DataFrame({'Features':selected_cols, 'Importances': importances})\n",
        "\n",
        "score = metrics(y_test, dtc_pred)\n",
        "acc = score.simple_acc()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title(f\"DTC Score : {acc}\")\n",
        "sns.barplot(x='Features', y='Importances', data=final_df)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p_JPXqwi6Osl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When trained with the df made with colon with the first 10 importance values from the previous trained model results, it gets 0.566 acc.\n",
        "\n",
        "indices = [X_train.columns.get_loc(k) for k in selected_cols]\n",
        "X_train_selected_cols = X_train.iloc[:, indices]\n",
        "\n",
        "indicex = [X_test.columns.get_loc(k) for k in selected_cols]\n",
        "X_test_selected_cols = X_test.iloc[:, indices]\n",
        "\n",
        "dtc_model3.fit(X_train_selected_cols, y_train)\n",
        "dtc_pred = dtc_model3.predict(X_test_selected_cols)\n",
        "\n",
        "score = metrics(y_test, dtc_pred)\n",
        "acc = score.simple_acc()\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "p6R9dZEg94TV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs_forward = SFS(svm_model, n_features_to_select=500, direction='forward', scoring='accuracy')\n",
        "sfs_forward.fit(X_train, y_train)\n",
        "\n",
        "selected_features = sfs_forward.get_support(True)\n",
        "\n",
        "svm_model.fit(X_train[:, selected_features], y_train)\n",
        "forward_selection_pred = svm_model.predict(X_test[:, selected_features])\n",
        "results.append(forward_selection_pred)"
      ],
      "metadata": {
        "id": "kmFIU3NUgRWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfs_backward = SFS(svm_model, n_features_to_select=3, direction='backward', scoring='accuracy')\n",
        "sfs_backward.fit(X_train, y_train)\n",
        "\n",
        "selected_features = sfs_forward.get_support(True)\n",
        "\n",
        "svm_model.fit(X_train[:, selected_features], y_train)\n",
        "backward_selection_pred = svm_model.predict(X_test[:, selected_features])\n",
        "results.append(backward_selection_pred)"
      ],
      "metadata": {
        "id": "96cjVluTgSo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in results:\n",
        "  score = metrics(y_test, i)\n",
        "  acc = score.simple_acc()\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "ShRltNDJXbNX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from scipy.stats import uniform, randint\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# result = {}\n",
        "# result2 = {}\n",
        "\n",
        "# svm_model = SVC()\n",
        "# rf_model = RandomForestClassifier()\n",
        "\n",
        "# params_grid_svm = {'kernel':('linear', 'rbf', 'polynomial'), 'C':[1, 5]}\n",
        "# params_random_svm = {'C': uniform(loc=0, scale=5),\n",
        "#               'kernel': ['linear', 'rbf', 'polynomial']}\n",
        "\n",
        "# params_grid_rf = {\n",
        "#     'n_estimators': [100, 300, 500],\n",
        "#     'max_features': ['sqrt', 'log2'],\n",
        "#     'max_depth': [10, 15, 20]\n",
        "# }\n",
        "# for i in range(10):\n",
        "#   params_random_rf = {\n",
        "#       'n_estimators': randint(150, 1000),\n",
        "#   }\n",
        "#   rnd = RandomizedSearchCV(rf_model, param_distributions=params_random_rf, n_iter=15)\n",
        "#   rnd.fit(X_train, y_train)\n",
        "\n",
        "#   result[i] = rnd.best_params_\n",
        "#   result2[i] = rnd.best_score_\n",
        "\n",
        "# params_grid_mlp = {'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
        "#                    'activation': ['logistic', 'tanh', 'relu'],\n",
        "#                    }\n",
        "# params_random_mlp = {'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
        "#                      'activation': ['logistic', 'tanh', 'relu'],}\n",
        "\n",
        "\n",
        "# grd = GridSearchCV(svm_model, params_grid)\n",
        "# grd.fit(X_train, y_train)\n",
        "\n",
        "# grd = GridSearchCV(rf_model, params_grid_rf)\n",
        "# grd.fit(X_train, y_train)\n",
        "\n",
        "# rnd = RandomizedSearchCV(svm_model, param_distributions=params_random, n_iter=10)\n",
        "# rnd.fit(X_train, y_train)\n",
        "\n",
        "# rnd = RandomizedSearchCV(rf_model, param_distributions=params_random_rf, n_iter=15)\n",
        "# rnd.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "WC0cpCTw8Yvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Best params with Grid Search: \", grd.best_params_)\n",
        "# print(\"Best score with Grid Search: \", grd.best_score_)\n",
        "\n",
        "# print(\"Best params with Random Search: \", rnd.best_params_)\n",
        "# print(\"Best score with Random Search: \", rnd.best_score_)\n",
        "\n",
        "# for i in result:\n",
        "#   print(result[i])\n",
        "#   print(result2[i])"
      ],
      "metadata": {
        "id": "WGqCaQAx5IrX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}